{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo # 4 - Big Data\n",
    "\n",
    "## Tarea # 3 \n",
    "## Autor: Jose Martinez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos de Entrada\n",
    "\n",
    "## Abandono de Banco\n",
    "\n",
    "Este conjunto de datos contiene detalles de los clientes de un banco y la variable objetivo es una variable binaria que refleja el hecho de si el cliente dejó el banco (cerró su cuenta) o si continúa siendo un cliente.\n",
    "\n",
    "### Features\n",
    "\n",
    "- `RowNumber`: Número de fila (Int)\n",
    "- `CustomerId`: Identificador del cliente (Int)\n",
    "- `Surname`: apellido del cliente (String)\n",
    "- `CreditScore`: puntaje de crédito del cliente (Number)\n",
    "- `Geography`: geografía del cliente (String)\n",
    "- `Gender`: Sexo del cliente (String)\n",
    "- `Age`: Edad del cliente (Int)\n",
    "- `Tenure`: Número de años que el cliente ha estado en el banco (Int)\n",
    "- `Balance`: estado de cuenta del cliente (Float)\n",
    "- `NumOfProducts`: numero de productos del cliente (Int)\n",
    "- `HasCrCard`: tiene tarjeta de crédito (Bool)\n",
    "- `IsActiveMember`: es un miembro activo (Bool)\n",
    "- `EstimatedSalary`: salario estimado del cliente (Float)\n",
    "\n",
    "### Objetivo Predictivo\n",
    "\n",
    "- `Exited`: si el cliente abandonó el banco (Bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/lib/python3.7/site-packages/pyspark')\n",
    "\n",
    "from pyspark.sql.types import (StringType, IntegerType, FloatType, \n",
    "                                StructField, StructType)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Bigdata: Tarea 3\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"postgresql-42.2.14.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"postgresql-42.2.14.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the schema of the dataframe\n",
    "churn_df = spark \\\n",
    "    .read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"path\", \"churn_modelling.csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .schema(StructType([\n",
    "                StructField(\"RowNumber\", IntegerType()),\n",
    "                StructField(\"CustomerId\", IntegerType()),\n",
    "                StructField(\"Surname\", StringType()),\n",
    "                StructField(\"CreditScore\", IntegerType()),\n",
    "                StructField(\"Geography\", StringType()),\n",
    "                StructField(\"Gender\", StringType()),\n",
    "                StructField(\"Age\", IntegerType()),\n",
    "                StructField(\"Tenure\", IntegerType()),\n",
    "                StructField(\"Balance\", FloatType()),\n",
    "                StructField(\"NumOfProducts\", IntegerType()),\n",
    "                StructField(\"HasCrCard\", IntegerType()),\n",
    "                StructField(\"IsActiveMember\", IntegerType()),\n",
    "                StructField(\"EstimatedSalary\", FloatType()),\n",
    "                StructField(\"Exited\", IntegerType())])) \\\n",
    "    .load()\n",
    "\n",
    "# Print the schema of the dataframe\n",
    "churn_df.printSchema()\n",
    "churn_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Se hace un primer filtrado para eliminar los registros que no tienen\n",
    "# información valiosa para calcular el modelo. Como lo son los registros\n",
    "# RowNumber, CustomerId, Surname. \n",
    "\n",
    "columns_kept = ['CreditScore', 'Gender', 'Age', 'Tenure', 'Geography',\n",
    "                'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "                'IsActiveMember', 'EstimatedSalary', 'Exited']\n",
    "\n",
    "columns_features = ['CreditScore', 'Gender', 'Age', 'Tenure', 'Geography',\n",
    "                    'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "                    'IsActiveMember', 'EstimatedSalary']\n",
    "\n",
    "selected_columns_df = churn_df.select(columns_kept)\n",
    "\n",
    "# Change Gender to int\n",
    "selected_columns_df = selected_columns_df.withColumn('Gender',\n",
    "                                                     when(selected_columns_df.Gender == 'Male', 1)\n",
    "                                                     .when(selected_columns_df.Gender == 'Female', 0)\n",
    "                                                     .otherwise(selected_columns_df.Gender))\n",
    "selected_columns_df = selected_columns_df .withColumn('Gender', selected_columns_df['Gender'].cast(IntegerType()))\n",
    "\n",
    "# Change Geography to int\n",
    "selected_columns_df = selected_columns_df.withColumn('Geography',\n",
    "                                                     when(selected_columns_df.Geography == 'Spain', 0)\n",
    "                                                     .when(selected_columns_df.Geography == 'France', 1)\n",
    "                                                     .when(selected_columns_df.Geography == 'Germany', 2)\n",
    "                                                     .otherwise(selected_columns_df.Geography))\n",
    "selected_columns_df = selected_columns_df .withColumn('Geography', selected_columns_df['Geography'].cast(IntegerType()))\n",
    "\n",
    "selected_columns_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos y Estadísticas Descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos información de los datos para verificar que no hay ningún\n",
    "# problema con los datos.\n",
    "selected_columns_df.describe(['CreditScore', 'Gender', 'Age', 'Tenure']).show()\n",
    "selected_columns_df.describe(['Balance', 'NumOfProducts', 'HasCrCard', 'Geography']).show()\n",
    "selected_columns_df.describe(['IsActiveMember', 'EstimatedSalary', 'Exited']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark_dist_explore import hist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(nrows=6, ncols=2)\n",
    "fig.set_size_inches(20, 20)\n",
    "\n",
    "hist(ax[0, 0], selected_columns_df.select('CreditScore'))\n",
    "ax[0, 0].set_title('CreditScore')\n",
    "\n",
    "hist(ax[0, 1], selected_columns_df.select('Gender'))\n",
    "ax[0, 1].set_title('Gender')\n",
    "\n",
    "hist(ax[1, 0], selected_columns_df.select('Age'))\n",
    "ax[1, 0].set_title('Age')\n",
    "\n",
    "hist(ax[1, 1], selected_columns_df.select('Tenure'))\n",
    "ax[1, 1].set_title('Tenure')\n",
    "\n",
    "hist(ax[2, 0], selected_columns_df.select('Balance'))\n",
    "ax[2, 0].set_title('Balance')\n",
    "\n",
    "hist(ax[2, 1], selected_columns_df.select('NumOfProducts'))\n",
    "ax[2, 1].set_title('NumOfProducts')\n",
    "\n",
    "hist(ax[3, 0], selected_columns_df.select('HasCrCard'))\n",
    "ax[3, 0].set_title('HasCrCard')\n",
    "\n",
    "hist(ax[3, 1], selected_columns_df.select('IsActiveMember'))\n",
    "ax[3, 1].set_title('IsActiveMember')\n",
    "\n",
    "hist(ax[4, 0], selected_columns_df.select('EstimatedSalary'))\n",
    "ax[4, 0].set_title('EstimatedSalary')\n",
    "\n",
    "hist(ax[4, 1], selected_columns_df.select('Geography'))\n",
    "ax[4, 1].set_title('Geography')\n",
    "\n",
    "hist(ax[5, 0], selected_columns_df.select('Exited'))\n",
    "ax[5, 0].set_title('Exited')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "\n",
    "Como se observa en el histograma de la variable objetivo, la cantidad de datos no es balanceada y hay muchos mas casos de abandono de cuenta que de no abandono. Por lo que se va a aplicar oversampling para mejorar la balanceación de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, array, lit\n",
    "from pyspark_dist_explore import hist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "selected_columns_df.groupby(\"Exited\").count().show()\n",
    "\n",
    "major_df = selected_columns_df.filter(selected_columns_df.Exited == 0)\n",
    "minor_df = selected_columns_df.filter(selected_columns_df.Exited == 1)\n",
    "ratio = int(major_df.count()/minor_df.count())\n",
    "print(\"ratio: {}\".format(ratio))\n",
    "\n",
    "a = range(ratio)\n",
    "\n",
    "# Duplicate the minority rows\n",
    "oversampled_df = minor_df.withColumn(\"dummy\", explode(array([lit(x) for x in a]))).drop('dummy')\n",
    "\n",
    "# Combine both oversampled minority rows and previous majority rows \n",
    "combined_df = major_df.unionAll(oversampled_df)\n",
    "\n",
    "combined_df.groupby(\"Exited\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para realizar operaciones más detalladas es necesario expresar las filas originales en vectores\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=columns_features,\n",
    "    outputCol='Features')\n",
    "\n",
    "vector_df = assembler.transform(combined_df)\n",
    "vector_df = vector_df.select(['Features', 'Exited'])\n",
    "vector_df.show()\n",
    "\n",
    "# Con la representación de vectores podemos calcular correlaciones\n",
    "pearson_matrix = Correlation.corr(vector_df, 'Features').collect()[0][0]\n",
    "sns.heatmap(pearson_matrix.toArray(), annot=True, fmt=\".2f\", cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputacion de valores faltantes\n",
    "\n",
    "El dataset fue revisando previamente para ver si existen valores faltantes. En este se cuanta con la fortuna de que no existen valores faltantes, por lo que no es necesario realizar ninguna acción. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización / Estandarización de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler, Normalizer\n",
    "\n",
    "# standard_normalizer = Normalizer(inputCol='features', outputCol='normFeatures')\n",
    "# normalize_df = standard_normalizer.transform(vector_df)\n",
    "# normalize_df.show()\n",
    "\n",
    "standard_scaler = StandardScaler(inputCol='Features', outputCol='scaledFeatures')\n",
    "scale_model = standard_scaler.fit(vector_df)\n",
    "\n",
    "scaled_df = scale_model.transform(vector_df)\n",
    "scaled_df = scaled_df.select(['scaledFeatures', 'Exited'])\n",
    "scaled_df.printSchema()\n",
    "scaled_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escritura a base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "# Covertir vector a columnas\n",
    "pre_df = (scaled_df.withColumn(\"scaledFeatures\", vector_to_array(\"scaledFeatures\"))).select([\"Exited\"] + [col(\"scaledFeatures\")[i].alias(columns_features[i]) for i in range(len(columns_features))])\n",
    "pre_df.printSchema()\n",
    "pre_df.show()\n",
    "\n",
    "# Almacenar el conjunto de datos limpio en la base de datos\n",
    "pre_df \\\n",
    "    .write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .mode('overwrite') \\\n",
    "    .option(\"url\", \"jdbc:postgresql://172.17.0.1:5433/postgres\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"testPassword\") \\\n",
    "    .option(\"dbtable\", \"tarea3\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading single DataFrame in Spark by retrieving all rows from a DB table.\n",
    "df = spark \\\n",
    "    .read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://172.17.0.1:5433/postgres\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"testPassword\") \\\n",
    "    .option(\"dbtable\", \"tarea3\") \\\n",
    "    .load()\n",
    "\n",
    "df.show()\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=columns_features,\n",
    "    outputCol='Features')\n",
    "\n",
    "vector_df = assembler.transform(selected_columns_df)\n",
    "vector_df = vector_df.select(['Features', 'Exited'])\n",
    "vector_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir dataset en conjunto de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (70 % training, 30 % test)\n",
    "training_df, test_df = scaled_df.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Imprimir tamano de los conjuntos de datos\n",
    "print(scaled_df.count())\n",
    "print(training_df.count())\n",
    "print(test_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de protocolo K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codigo tomado de https://stackoverflow.com/questions/53600615/cross-validation-metrics-with-pyspark\n",
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.sql.functions import rand\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "TestResult = collections.namedtuple(\"TestResult\", [\"params\", \"metrics\"])\n",
    "\n",
    "class CrossValidatorVerbose(CrossValidator):\n",
    "\n",
    "    def _fit(self, dataset):\n",
    "        folds = []\n",
    "        est = self.getOrDefault(self.estimator)\n",
    "        epm = self.getOrDefault(self.estimatorParamMaps)\n",
    "        numModels = len(epm)\n",
    "\n",
    "        eva = self.getOrDefault(self.evaluator)\n",
    "        metricName = eva.getMetricName()\n",
    "        nFolds = self.getOrDefault(self.numFolds)\n",
    "        seed = self.getOrDefault(self.seed)\n",
    "        h = 1.0 / nFolds\n",
    "\n",
    "        randCol = self.uid + \"_rand\"\n",
    "        df = dataset.select(\"*\", rand(seed).alias(randCol))\n",
    "        metrics = [0.0] * numModels\n",
    "\n",
    "        for i in range(nFolds):\n",
    "            folds.append([])\n",
    "            foldNum = i + 1\n",
    "            print(\"Comparing models on fold %d\" % foldNum)\n",
    "\n",
    "            validateLB = i * h\n",
    "            validateUB = (i + 1) * h\n",
    "            condition = (df[randCol] >= validateLB) & (df[randCol] < validateUB)\n",
    "            validation = df.filter(condition)\n",
    "            train = df.filter(~condition)\n",
    "\n",
    "            for j in range(numModels):\n",
    "                paramMap = epm[j]\n",
    "                model = est.fit(train, paramMap)\n",
    "                # TODO: duplicate evaluator to take extra params from input\n",
    "                prediction = model.transform(validation, paramMap)\n",
    "                metric = eva.evaluate(prediction)\n",
    "                metrics[j] += metric\n",
    "\n",
    "                avgSoFar = metrics[j] / foldNum\n",
    "                print(\"params: %s\\t%s: %f\\tavg: %f\" % (\n",
    "                    {param.name: val for (param, val) in paramMap.items()},\n",
    "                    metricName, metric, avgSoFar))\n",
    "                \n",
    "                predictionLabels = prediction.select(\"prediction\", \"Exited\")\n",
    "                allMetrics = BinaryClassificationMetrics(predictionLabels.rdd)\n",
    "                folds[i].append(TestResult(paramMap.items(), allMetrics))\n",
    "                \n",
    "\n",
    "        if eva.isLargerBetter():\n",
    "            bestIndex = np.argmax(metrics)\n",
    "        else:\n",
    "            bestIndex = np.argmin(metrics)\n",
    "\n",
    "        bestParams = epm[bestIndex]\n",
    "        bestModel = est.fit(dataset, bestParams)\n",
    "        avgMetrics = [m / nFolds for m in metrics]\n",
    "        bestAvg = avgMetrics[bestIndex]\n",
    "        print(\"Best model:\\nparams: %s\\t%s: %f\" % (\n",
    "            {param.name: val for (param, val) in bestParams.items()},\n",
    "            metricName, bestAvg))\n",
    "\n",
    "        return self._copyValues(CrossValidatorModel(bestModel, avgMetrics)), folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 1: Regresión Logística "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "\n",
    "df = training_df.select('scaledFeatures', 'Exited')\n",
    "df.show()\n",
    "\n",
    "lr = LogisticRegression(featuresCol='scaledFeatures', labelCol='Exited', maxIter=10)\n",
    "grid = ParamGridBuilder().addGrid(param=lr.maxIter, values=[10]).build()\n",
    "# lr_model = lr.fit(df)\n",
    "\n",
    "# Implementa k-Folds e imprime informacion por cada iteracion\n",
    "cv = CrossValidatorVerbose(estimator=lr,\n",
    "                           estimatorParamMaps=grid,\n",
    "                           evaluator=BinaryClassificationEvaluator(labelCol='Exited'),\n",
    "                           numFolds=5)\n",
    "\n",
    "cvlr_model, lr_folds = cv.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "df = training_df.select('scaledFeatures', 'Exited')\n",
    "df.show()\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol='scaledFeatures', labelCol='Exited', maxDepth=4)\n",
    "grid = ParamGridBuilder().addGrid(rf.maxDepth, values=[4]).build()\n",
    "\n",
    "# Implementa k-Folds e imprime informacion por cada iteracion\n",
    "cv = CrossValidatorVerbose(estimator=rf,\n",
    "                           estimatorParamMaps=grid,\n",
    "                           evaluator=BinaryClassificationEvaluator(labelCol='Exited'),\n",
    "                           numFolds=5)\n",
    "\n",
    "cvrf_model, rf_folds = cv.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "df = training_df.select('scaledFeatures', 'Exited')\n",
    "df.show()\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol='scaledFeatures', labelCol='Exited', maxDepth = 4)\n",
    "grid = ParamGridBuilder().addGrid(dt.maxDepth, values=[4]).build()\n",
    "\n",
    "# Implementa k-Folds e imprime informacion por cada iteracion\n",
    "cv = CrossValidatorVerbose(estimator=dt,\n",
    "                           estimatorParamMaps=grid,\n",
    "                           evaluator=BinaryClassificationEvaluator(labelCol='Exited'),\n",
    "                           numFolds=5)\n",
    "\n",
    "cvdt_model, dt_folds = cv.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación del conjunto de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación y almacenado de modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# cv = CrossValidator(estimator=lr,\n",
    "#                            estimatorParamMaps=grid,\n",
    "#                            evaluator=BinaryClassificationEvaluator(labelCol='Exited'),\n",
    "#                            numFolds=5)\n",
    "\n",
    "# print(cvlr_model.subModels)\n",
    "\n",
    "# print(cvlr_model.avgMetrics[0])\n",
    "\n",
    "# print(cvlr_model.extractParamMap())\n",
    "\n",
    "\n",
    "# # Make prediction\n",
    "# predictionAndTarget = predictions.select(\"Exited\", \"prediction\")\n",
    "\n",
    "# # Create both evaluators\n",
    "# metrics_binary = BinaryClassificationMetrics(predictionAndTarget.rdd.map(tuple))\n",
    "# acc = metrics_binary.accuracy\n",
    "# f1 = metrics_binary.fMeasure(1.0)\n",
    "# precision = metrics_binary.precision(1.0)\n",
    "# recall = metrics_binary.recall(1.0)\n",
    "# auc = metrics_binary.areaUnderROC\n",
    "\n",
    "# print('Accuracy:', acc)\n",
    "# print('F1:', f1)\n",
    "# print('Precision:', precision)\n",
    "# print('Recall:', recall)\n",
    "# print('Area Under ROC:', auc)\n",
    "\n",
    "# print('Pesos: {}\\n b: {}'.format(lr_model.coefficients, lr_model.intercept))\n",
    "\n",
    "# print('RMSE: {} r2: {}'.format(\n",
    "#     lr_model.summary.rootMeanSquaredError,\n",
    "#     lr_model.summary.r2))\n",
    "\n",
    "# scaled_df.describe().show()\n",
    "# predictions = lr_model.transform(test_df)\n",
    "\n",
    "\n",
    "# from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Exited')\n",
    "\n",
    "# Coefficients \n",
    "# beta = np.sort(cvlr_model.coefficients)\n",
    "# plt.plot(beta)\n",
    "# plt.ylabel('Beta Coefficients')\n",
    "# plt.show()\n",
    "\n",
    "# # Area under ROC\n",
    "# trainingSummary = cvlr_model.summary\n",
    "# roc = trainingSummary.roc.toPandas()\n",
    "# plt.plot(roc['FPR'],roc['TPR'])\n",
    "# plt.ylabel('False Positive Rate')\n",
    "# plt.xlabel('True Positive Rate')\n",
    "# plt.title('ROC Curve')\n",
    "# plt.show()\n",
    "# print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# # Precision and recall.\n",
    "# pr = trainingSummary.pr.toPandas()\n",
    "# plt.plot(pr['recall'],pr['precision'])\n",
    "# plt.ylabel('Precision')\n",
    "# plt.xlabel('Recall')\n",
    "# plt.show()\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = cvlr_model.transform(test_df.select('scaledFeatures', 'Exited'))\n",
    "predictions.show()\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='Exited')\n",
    "print('Test Area Under ROC', evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación y almacenado de modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación y almacenado de modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PORQUE DIO BIEN? "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
